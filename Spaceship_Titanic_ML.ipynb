{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3092b815-c43b-4998-b451-09ef5d0266ac",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - A Supervised Classification Machine Learning Problem\n",
    "\n",
    "# Background: \n",
    "Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "![Planetary Systems](./Images/55_Cancri_E_from_Earth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a462b-569c-49ee-81f6-2eef90ca8fc2",
   "metadata": {},
   "source": [
    "# File and Data Field Descriptions\n",
    "**Personal records recovered from the ship's damaged computer system**\n",
    "* **train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "    - PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "    - HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "    - CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "    - Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "    - Destination - The planet the passenger will be debarking to.\n",
    "    - Age - The age of the passenger.\n",
    "    - VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "    - RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "    - Name - The first and last names of the passenger.\n",
    "    - Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "* **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
    "* **sample_submission.csv** - A submission file in the correct format.\n",
    "    - PassengerId - Id for each passenger in the test set.\n",
    "    - Transported - The target. For each passenger, predict either True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ab566-72e6-4e4f-b192-e02e4c6457e7",
   "metadata": {},
   "source": [
    "### Define the Problem: \n",
    "1. What is the problem\n",
    "    * Informal Description - I need a program that will predict which passengers were transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly using a set of personal records recovered from the ship's damaged computer system. <br><br>\n",
    "    * Formalism \n",
    "        * Task(T) Classify a passenger (not seen in training) as being Transported (\"True or False\")\n",
    "        * Experience(E) A list of passengers' personal records (the training set) indicating if they were Transported (\"True or False\") (Supervised Learning)\n",
    "        * Performance(P) Classification accuracy, the number of passengers predicted correctly out of all passengers considered as a percentage<br><br>\n",
    "2. Why does the problem need to be solved?\n",
    "    * Motivation - I am solving this problem as a learning exercise in applying Machine Learning techniques.\n",
    "    * Solution Use - The solution's lifetime is short-lived and will be submitted for the Kaggle competition (no maintenance required)<br><br>\n",
    "3. How would I solve the problem?<br><br>\n",
    "    * In a systematic fashion using a checklist<br><br>\n",
    "source: https://machinelearningmastery.com/machine-learning-checklist/<br><br>\n",
    "![ML Process to solve the problem](./Images/Machine-Learning-for-Programmers-Select-Tools-e1439699936331.png)\n",
    "    * Define the Problem\n",
    "    * Prepare the Data: Data Cleaning and Imputing missing values\n",
    "    * Spot Check Algorithms: Baseline with simple model(s) to gain inital insight (i.e., feature importances) and benchmark classification accuracy (i.e., LogisticRegressionClassifier and RandomForestClassifier)\n",
    "    * Improve the Results: Train and evaluate more complex models (like Deep Neural Networks) to improve classification accuracy\n",
    "    * Present the Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453d740-32c6-4ae2-a583-9fb033d7e386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Assumptions:\n",
    "    * A passenger's location on the ship when the collision occured matters to the model\n",
    "        Related factors include:\n",
    "            - Where is the passenger's cabin on the ship? Side, Deck, Cabin_Number\n",
    "            - Was the passenger in their cabin at the time of the collision? Spending records indicate activity\n",
    "            - What was the passenger's Destination? Passengers about to debark were likely not in their cabin\n",
    "            - What was the passenger's HomePlanet? Passengers who recently embarked were likely in their cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273adf0e-fdea-41ca-89e4-8ab7e3952e35",
   "metadata": {},
   "source": [
    "### Prepare the Data:\n",
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b284859-c40e-4ca0-af76-d13ce7a8a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn and set_theme\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# import regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661832e7-1923-4cfe-a1d4-45347e823708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn dependencies\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79635fe-1461-4011-bc24-6d31c67fad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies from tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b44138-ddd0-41f6-aeb0-fae507bce9d5",
   "metadata": {},
   "source": [
    "#### Extract the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a97f18e-68e1-47a0-af20-8c1c04688f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import training and testing csv files from Data folder\n",
    "input_file_path = \"./Data/train.csv\"\n",
    "training_df = pd.read_csv(input_file_path)\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74931c94-bfc7-4e18-b7c6-e28110a843e1",
   "metadata": {},
   "source": [
    "#### Set PassengerId as the index\n",
    "The PassengerId is a unique value and is required as part of the contest submission. The PassengerId will be set as the index using set_index method so that any data cleaning retains the PassengerId value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed02fc48-5eac-4263-8b96-f34f4430434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_02</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004_01</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276_01</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9278_01</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279_01</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280_01</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280_02</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PassengerId HomePlanet CryoSleep     Cabin    Destination   Age  \\\n",
       "PassengerId                                                                   \n",
       "0001_01         0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0   \n",
       "0002_01         0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0   \n",
       "0003_01         0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   \n",
       "0003_02         0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0   \n",
       "0004_01         0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0   \n",
       "...                 ...        ...       ...       ...            ...   ...   \n",
       "9276_01         9276_01     Europa     False    A/98/P    55 Cancri e  41.0   \n",
       "9278_01         9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0   \n",
       "9279_01         9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0   \n",
       "9280_01         9280_01     Europa     False   E/608/S    55 Cancri e  32.0   \n",
       "9280_02         9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0   \n",
       "\n",
       "               VIP  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "PassengerId                                                                \n",
       "0001_01      False          0.0        0.0           0.0     0.0     0.0   \n",
       "0002_01      False        109.0        9.0          25.0   549.0    44.0   \n",
       "0003_01       True         43.0     3576.0           0.0  6715.0    49.0   \n",
       "0003_02      False          0.0     1283.0         371.0  3329.0   193.0   \n",
       "0004_01      False        303.0       70.0         151.0   565.0     2.0   \n",
       "...            ...          ...        ...           ...     ...     ...   \n",
       "9276_01       True          0.0     6819.0           0.0  1643.0    74.0   \n",
       "9278_01      False          0.0        0.0           0.0     0.0     0.0   \n",
       "9279_01      False          0.0        0.0        1872.0     1.0     0.0   \n",
       "9280_01      False          0.0     1049.0           0.0   353.0  3235.0   \n",
       "9280_02      False        126.0     4688.0           0.0     0.0    12.0   \n",
       "\n",
       "                          Name  Transported  \n",
       "PassengerId                                  \n",
       "0001_01        Maham Ofracculy        False  \n",
       "0002_01           Juanna Vines         True  \n",
       "0003_01          Altark Susent        False  \n",
       "0003_02           Solam Susent        False  \n",
       "0004_01      Willy Santantines         True  \n",
       "...                        ...          ...  \n",
       "9276_01      Gravior Noxnuther        False  \n",
       "9278_01        Kurta Mondalley        False  \n",
       "9279_01           Fayey Connon         True  \n",
       "9280_01       Celeon Hontichre        False  \n",
       "9280_02       Propsh Hontichre         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.set_index('PassengerId' , inplace=True, drop=False)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95b4d1ec-837f-4a36-a7c4-1549ab45c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6606 entries, 0001_01 to 9280_02\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   6606 non-null   object \n",
      " 1   HomePlanet    6606 non-null   object \n",
      " 2   CryoSleep     6606 non-null   object \n",
      " 3   Cabin         6606 non-null   object \n",
      " 4   Destination   6606 non-null   object \n",
      " 5   Age           6606 non-null   float64\n",
      " 6   VIP           6606 non-null   object \n",
      " 7   RoomService   6606 non-null   float64\n",
      " 8   FoodCourt     6606 non-null   float64\n",
      " 9   ShoppingMall  6606 non-null   float64\n",
      " 10  Spa           6606 non-null   float64\n",
      " 11  VRDeck        6606 non-null   float64\n",
      " 12  Name          6606 non-null   object \n",
      " 13  Transported   6606 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 729.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop rows where all values are na\n",
    "training_df = training_df.copy()\n",
    "training_df.dropna(inplace=True)\n",
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b4fa2-781d-4be1-83a4-fafdbc90e228",
   "metadata": {},
   "source": [
    "#### Explore the Data\n",
    "##### What are the value counts for the Target (Transported)?\n",
    "Is this a balanced or imbalanced problem? Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b99ce-940b-4035-8f54-94af309f1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the target variable \"Transported\"\n",
    "Target = training_df[\"Transported\"].value_counts()\n",
    "Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86383c-0a9c-4c59-a662-53d06e0270bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the value count of the Target\n",
    "Target.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db85dc-020f-4828-a001-7be6426343b9",
   "metadata": {},
   "source": [
    "##### What values are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228938e-342d-44ef-bb61-298216d1364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the missing values using seaborn heatmap\n",
    "sns.heatmap(training_df.isnull(), cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38ea47-0217-4a77-81df-ce3fa5869108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of missing values for each col in training_df\n",
    "# use training_df[column].isnull().sum() within list comprehension\n",
    "# list comprehension template is: [expression, for col in columns, where conditional is true]\n",
    "col_with_missing_values = [print(col, training_df[col].isnull().sum()) for col in training_df.columns if training_df[col].isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacb005-d588-40e0-920f-55867a228829",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Strategy for missing values and combined columns:\n",
    "* HomePlanet (201)\n",
    "    - Inital Strategy: Impute missing values for HomePlanet with 'most_frequent'  - Earth\n",
    "    - Follow-on Strategy: Use Supervised Classification to predict missing HomePlanet<br><br>\n",
    "    \n",
    "* CryoSleep (217)\n",
    "    - Inital Strategy: Impute CryoSleep with 'most_frequent' - False\n",
    "    - Follow-on Strategy: Use KKN to Classify missing CryoSleep<br><br>\n",
    "    \n",
    "* Cabin (199)\n",
    "    - Inital Strategy: Drop missing values then decompose Cabin into deck, num, side\n",
    "    - Follow-on Strategy: Use KNN to Classify missing Cabin<br><br>\n",
    "\n",
    "* Destination (182)\n",
    "    - Inital Strategy: Impute Destination with 'most_frequent' - TRAPPIST-1e\n",
    "    - Follow-on Strategy: Use Supervised Classification to predict missing Destination<br><br>\n",
    "    \n",
    "* Age (179)\n",
    "    - Inital Strategy: Imput Age with 'most_frequent' (median age) - 27\n",
    "    - Follow-on Strategy: Use Supervised Regression to predict missing Age<br><br>\n",
    "\n",
    "* VIP (203)\n",
    "    - Inital Strategy: Impute VIP status with 'most_frequent' - False\n",
    "    - Follow-on Stragegy: Use KKN to Classify missing VIP status<br><br>\n",
    "\n",
    "* RoomService (181), FoodCourt (183), ShoppingMall (208), Spa (183), VRDeck (188)\n",
    "    - Inital Strategy: Impute missing values for RoomService, FoodCourt, ShoppingMall, Spa, VRDeck with 0<br><br>\n",
    "\n",
    "* Name (200) \n",
    "    - Inital Strategy: Drop missing values then just keep last name\n",
    "    - Follow-on Strategy: Use unsupervised learning to bin names and then classify the 'class' using K-Nearest Neighbor<br><br>\n",
    "\n",
    "* PassengerId (0)\n",
    "    - Inital Strategy: use string.split to split into GroupId and GroupCount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6c2bf-97ea-4e71-8ab9-3696a2c7e7de",
   "metadata": {},
   "source": [
    "#### The imputing strategy plans to use others in the same group if application\n",
    "Create column Group_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70b30d-4084-4b61-9b9a-ca4d12b02614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names \n",
    "training_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f976582-9c94-4f07-84ef-aa6caa1beb95",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### PassengerId: Breakout into GroupId and GroupCount and drop PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6908087-5aac-4ffe-a4b6-5d0bff6e9329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GroupId and GroupCount from PassengerId using str.split()\n",
    "# PassengerId - A unique Id for each passenger. \n",
    "# Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. \n",
    "# People in a group are often family members, but not always.\n",
    "training_df = training_df.copy()\n",
    "training_df[[\"GroupId\", \"Count_in_Group\"]] = training_df[\"PassengerId\"].str.split(\"_\", expand=True)\n",
    "\n",
    "# drop Name and First_Name\n",
    "training_df.drop(columns=['PassengerId'], inplace=True)\n",
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf809f-7b04-4f53-ad43-3e9a25d41332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns to put Deck, Cabin_Number, Side together and drop Cabin\n",
    "# extract_training_df.columns\n",
    "columns = ['GroupId', 'Count_in_Group', 'Name', 'HomePlanet',  'Destination', 'Cabin',  \n",
    "      'Age', 'CryoSleep','VIP', 'RoomService', 'FoodCourt', 'ShoppingMall',\n",
    "       'Spa', 'VRDeck', 'Transported' ]\n",
    "training_df = training_df[columns]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554262cb-d15c-404f-9722-51cd8fb4ae84",
   "metadata": {},
   "source": [
    "#### Convert Count_in_Group to Group_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601134e-da50-47d5-be7d-57cfd00a5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtype of GroupCount\n",
    "training_df['Count_in_Group'].dtypes\n",
    "\n",
    "# recast object to int using \n",
    "training_df['Count_in_Group'] = training_df['Count_in_Group'].astype(int)\n",
    "\n",
    "# check dtype\n",
    "training_df['Count_in_Group'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f50bf0e-23dd-41bd-83fe-8e3fd8bf3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert GroupId to numeric (drops leading zeros)\n",
    "training_df['GroupId'] = pd.to_numeric(training_df['GroupId'])\n",
    "# training_df['GroupId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2954df7-408b-4c2f-8b01-39b7d5184e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of GroupIds to iterate over\n",
    "Group_Ids =(list(training_df['GroupId']))\n",
    "# Group_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5a054-1cf6-422f-95db-f871b8882186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group_Size will be the max Count_in_Group for each unique GroupId\n",
    "training_df['Group_Size'] = [max(training_df.loc[training_df['GroupId'] == Group_Id]['Count_in_Group']) for Group_Id in Group_Ids]\n",
    "# training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497fcee-c944-4cb1-a773-acb355366ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4974a-216c-4524-aac0-9b8310a84ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder and drop GroupCount\n",
    "# training_df.columns\n",
    "columns = ['GroupId', 'Group_Size', 'Name', 'HomePlanet', 'Destination', 'Cabin',\n",
    "       'Age', 'CryoSleep', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall',\n",
    "       'Spa', 'VRDeck', 'Transported']\n",
    "training_df = training_df[columns]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ee0ab-d86f-4f7a-819a-93f58a8a46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view distribution of Group_Size\n",
    "training_df['Group_Size'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f2806-d181-48d6-a95f-b0d2142635ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Impute HomePlanet with 'most_frequent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1bac4-99b9-4f8e-b94e-d4c640efb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View passengers missing values for HomePlanet\n",
    "training_df.loc[training_df['HomePlanet'].isnull()].where(training_df['Group_Size'].isin([2,3,4,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2b1e1-9a45-4a8b-9143-fe5974198f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the most frequent value for HomePlanet\n",
    "training_df['HomePlanet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede73e8f-0511-4809-b3de-8118e254ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital stratgy\n",
    "# fillna with Earth\n",
    "training_df['HomePlanet'].fillna('Earth', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e53e3-5314-4223-b630-19de13d3ac1d",
   "metadata": {},
   "source": [
    "##### Impute CryoSleep with 'most_frequent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935899c5-c0ec-4ab0-afd9-65f2e0ab4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most common value for CryoSleep\n",
    "CryoSleep = training_df['CryoSleep'].value_counts()\n",
    "CryoSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d8703-034d-45b4-802c-689be5388567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Missing Values for CryoSleep to most common value (False)\n",
    "training_df['CryoSleep'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17c3cb-6122-4e3f-b99f-d648e328c41e",
   "metadata": {},
   "source": [
    "##### Breakout Cabin into deck, cabin number and side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfb685-7cee-4aad-a8a4-a3899a3bacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract deck cabin number and side from Cabin using str.split()\n",
    "# Cabin - The cabin number where the passenger is staying. \n",
    "# Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "\n",
    "# drop missing values (initally)\n",
    "# make a copy \n",
    "extract_training_df = training_df.copy()\n",
    "extract_training_df.dropna(subset=['Cabin'], inplace=True)\n",
    "\n",
    "# split out Deck, Cabin_Number, Side\n",
    "extract_training_df[[\"Deck\", \"Cabin_Number\", \"Side\"]] = extract_training_df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "extract_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5438c79-2e7d-42bd-9431-363c1374071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view columns\n",
    "extract_training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befad5e6-bdfd-43d8-843b-5111c99a5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns to put Deck, Cabin_Number, Side together and drop Cabin\n",
    "# extract_training_df.columns\n",
    "columns = ['PassengerId', 'HomePlanet', 'CryoSleep', 'Deck', 'Cabin_Number', 'Side', 'Destination', 'Age',\n",
    "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
    "       'Name', 'Transported', ]\n",
    "extract_training_df = extract_training_df[columns]\n",
    "extract_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbd91a-ad75-4baf-ba7c-0c9ff72bbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side counts\n",
    "Side = extract_training_df['Side'].value_counts()\n",
    "Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26938d4d-d401-4207-8202-004af9ec0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deck counts\n",
    "Deck = extract_training_df['Deck'].value_counts()\n",
    "Deck\n",
    "\n",
    "# in the original vessal \n",
    "# Deck A is a promenade deck\n",
    "# Cabins are on decks B to G\n",
    "# Deck T is for crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd350866-2637-4543-9fff-4eec46049d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique cabins were assigned?\n",
    "Cabins_Assigned = len(pd.unique(extract_training_df['Cabin_Number']))\n",
    "Cabins_Assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a886b-0f20-47ae-808b-285c1de31ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cabin_Numbers = extract_training_df['Cabin_Number'].value_counts()\n",
    "Cabin_Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994b064-9a28-4f60-92ea-5ab079f21c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Destination: Impute with 'most_frequent' TRAPPIST-1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc21ebd-d7cf-443d-abdb-27a00643b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most common value for Destination\n",
    "Destination = extract_training_df['Destination'].value_counts()\n",
    "Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4341567-5d48-496c-9674-54813855882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Missing Values for Destination to TRAPPIST-1e\n",
    "\n",
    "# create a copy\n",
    "extract_training_copy_df = extract_training_df.copy()\n",
    "extract_training_copy_df['Destination'].fillna('TRAPPIST-1e', inplace=True)\n",
    "\n",
    "# check results\n",
    "Destination = extract_training_copy_df['Destination'].value_counts()\n",
    "Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58039fac-077e-4c2a-a70b-bdd9be35977c",
   "metadata": {},
   "source": [
    "##### Age: Impute with 'median age' (27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b3436-4596-4b1d-96f9-5a4ff5ded98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify name of dataframe \n",
    "training_df = extract_training_copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2f2b5-8a24-4869-a3ed-277a4f130bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find median value for Age\n",
    "Age = training_df['Age']\n",
    "Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a74178-4b3a-49bf-b1ab-ad9df0ddd335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Missing Values for Age with median value (27)\n",
    "training_df['Age'].fillna(27, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c67e2db-53f9-4f7e-baaa-c5eb4e86ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of age in a box plot\n",
    "ax = sns.boxplot(x=Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb936409-e052-4192-8a1d-6d5839c358bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### VIP Status: Impute with 'most_frequent' False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced8633-1e60-4d91-b58a-d9beaff29c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fillna method and a dictionary of fill values to impute VIP, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck with a 0\n",
    "values = {\"VIP\": False}\n",
    "training_df.fillna(value=values, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dd137-27db-41d1-bb11-ab00ceb869c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: Impute with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5d073-85bd-49dd-bc0a-550fe045ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the summary statistics for RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "training_df.describe()[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80101ae-9404-4cee-8a7d-6a13c5990818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fillna method and a dictionary of fill values to impute VIP, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck with a 0\n",
    "values = {\"RoomService\": 0, \"FoodCourt\": 0, \"ShoppingMall\": 0, \"Spa\": 0, \"VRDeck\": 0}\n",
    "training_df.fillna(value=values, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e36d5a-dbe8-428b-9a68-29e44b422beb",
   "metadata": {},
   "source": [
    "##### Name: Keep just Last_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7971b-bcb1-4d26-a14c-ec9d484c7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values for Name (initally)\n",
    "# make a copy \n",
    "training_df = training_df.copy()\n",
    "training_df.dropna(subset=['Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06ede5-7751-45e4-9c87-dff8c18e86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep just last name\n",
    "training_df[[\"First_Name\", \"Last_Name\"]] = training_df[\"Name\"].str.split(\" \", expand=True)\n",
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64973a-0096-45be-9ac9-120438828a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Name and First_Name\n",
    "training_df.drop(columns=['Name', 'First_Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85258f-d1ed-4797-9ef8-265b49dea7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c79a4-a46b-458c-9bf4-e9927d716e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of missing values for each col in training_df\n",
    "# use training_df[column].isnull().sum() within list comprehension\n",
    "# list comprehension template is: [expression, for col in columns, where conditional is true]\n",
    "col_with_missing_values = [print(col, training_df[col].isnull().sum()) for col in training_df.columns if training_df[col].isnull().sum() > 0]\n",
    "col_with_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b33f1a-d5cc-41dc-b739-1f620735b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the missing values using seaborn heatmap\n",
    "sns.heatmap(training_df.isnull(), cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d385fd-c352-46ca-bdd4-e91b2635463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine dtypes\n",
    "training_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a287f6-f9ee-445a-8951-7037c0cee22b",
   "metadata": {},
   "source": [
    "#### Convert Columns from Booleans into Integers with astypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5dd059-0b80-4138-a050-28321d9de369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are our boolean value columns\n",
    "columns_boolean = training_df.select_dtypes(include='bool').columns\n",
    "columns_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b63c7e-52be-4030-9d41-ef3d936776d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert boolean to numeric\n",
    "for col in ['CryoSleep', 'VIP']:\n",
    "    training_df[col] = training_df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb687b7-6722-4da2-9d6c-774a7695c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for what are our boolean value columns\n",
    "columns_boolean = training_df.select_dtypes(include='bool').columns\n",
    "columns_boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b9c8e-83b6-48cb-b331-49893699491a",
   "metadata": {},
   "source": [
    "### Split data into feature matrix (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55967a7e-01f9-4830-ac45-df9700c1c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "X = training_df.drop(columns='Transported')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19347504-9d77-4c98-af64-a3d57fa6db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target\n",
    "y = training_df['Transported']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c32bb-36dd-4bff-b275-17c9d81ebd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all columns are object or numeric (for use in pd.get_dummies)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf7ebe-7411-4ca4-89e8-62b7bd5c8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Cabin_Number to an int\n",
    "X['Cabin_Number'] = X['Cabin_Number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c851f5f-27c1-4dab-bda0-05ba62729f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for dtype for Cabin_Number\n",
    "X['Cabin_Number'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f263c-b941-4222-a9d8-5a384ec4e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert GroupId to int\n",
    "X['GroupId'] = X['GroupId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ff94d-dc92-4c78-bd4f-e228530f1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for dtype for GroupId\n",
    "X['GroupId'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bdfbc3-2173-4fd0-8573-e24cc4abacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert GroupId to int\n",
    "X['GroupCount'] = X['GroupCount'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123644c4-463a-4aca-a0da-8b66130d4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again for dtype for GroupId\n",
    "X['GroupCount'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddaa03-458b-487f-a6da-e9beff01d16f",
   "metadata": {},
   "source": [
    "### Save Clean_training_df as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40394384-be3d-4e01-865d-3c8f22e3f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean_training_df as csv file\n",
    "clean_training_df.to_csv('./Data/clean_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e86f1-8608-435f-95b7-bf03e0fa5998",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e1a72-089e-4176-8e4d-e0fc11358715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the shape of clean_training_df\n",
    "clean_training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdf110-16db-4ce9-ad15-e83c463a9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the balance/imbalance of the target\n",
    "y_value_counts = y.value_counts()\n",
    "y_value_counts\n",
    "\n",
    "# this is a balanced clasification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eafb28-a7a1-4804-bdcc-fc3ee9090998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are our categorical value columns\n",
    "columns_obj = X.select_dtypes(include='object').columns\n",
    "print(f\"There are {len(columns_obj)} columns with a dtype of 'object'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8dfe78-47af-4f94-a6ae-331feed3d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the 6 columns:\n",
    "columns_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f65642-335f-4335-b341-e75b1e8e4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine all the columns and each columns value_counts\n",
    "for column in X[columns_obj]:\n",
    "    print(column, \"\\n\", X[column].value_counts())\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d5f08-fce6-4fd2-ac42-b9119ed72bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns will be converted to numeric values using Pandas get_dummies\n",
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979ee1e-2946-4fa8-bcf5-d95154a3b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all columns are now numeric\n",
    "X_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae276a3-7854-48d4-a3fd-baf3df9ad7a3",
   "metadata": {},
   "source": [
    "### StandarScaler: Transform the feature matrix using standard scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516936e3-af4b-4273-bd17-152c746e5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_encoded using StandardScaler\n",
    "data_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d45824-ad6d-46dc-be7c-332a39b94a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform our X_encoded\n",
    "X_encoded_std_scaled = data_scaler.fit_transform(X_encoded)\n",
    "\n",
    "# examine the first row\n",
    "X_encoded_std_scaled[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c621327d-c882-42a1-9662-c835c89152a8",
   "metadata": {},
   "source": [
    "### Establish a Baseline for model performance using LogisticRegress as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d6dce-856e-474a-b217-e5f982ef26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# note: y is not scaled but the extension _ss is added to help me remember to use the scaled feature matrix values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded_std_scaled, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d275215-3b98-4145-a30c-b3d95e18e6bf",
   "metadata": {},
   "source": [
    "### Establish a Baseline for model performance using LogisticRegress as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa3495-ac3e-4f90-9158-6de55cf09ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Logistic Regression Model\n",
    "# increased max_iter=1000 due to inability of 'lbfgs' solver to converge\n",
    "LR_clf_baseline = LogisticRegression(solver='lbfgs', random_state=1, max_iter=100)\n",
    "LR_clf_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efaba8d-a410-4211-9b6e-efc4f819dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our model with our data (training)\n",
    "LR_clf_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ecffb4-7217-4f7e-b2c9-31781e4ae4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions using predict() method\n",
    "y_pred_baseline = LR_clf_baseline.predict(X_test)\n",
    "y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2815f1-ee12-4cf3-9d95-9a9eae2ba365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the data\n",
    "pd.DataFrame({\"Prediction\": y_pred_baseline, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1b499-1b94-49ef-93ad-5f707550bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model accuracy\n",
    "balanced_accuracy_score(y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f219e-63e8-4022-a6db-47da612eb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(cm_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aff1e6-f009-4006-a905-e028bb7dd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_baseline,display_labels= LR_clf_baseline.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# save the image\n",
    "plt.savefig(\"./Images/Baseline_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e7b45-224d-41f1-a94d-7aaa10d93fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the classification report\n",
    "# report = classification_report(y_test, y_pred_baseline, output_dict=True)\n",
    "\n",
    "baseline_report = classification_report(y_test, y_pred_baseline)\n",
    "print(\"Baseline\")\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1f30b-93c3-4a39-a90c-69eb4bdfb1ce",
   "metadata": {},
   "source": [
    "### Balanced Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c93d9-8587-4017-8924-c9a717f06ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda399c-04ee-442c-9be9-f8c98e7b86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit predict using the BalancedRandomForestClassifier\n",
    "\n",
    "# model\n",
    "brf_model = BalancedRandomForestClassifier(n_estimators= 100,random_state=1)\n",
    "\n",
    "# fit\n",
    "brf_model = brf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = brf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3d5e4-ae7f-4dcd-a6b4-166593318504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "print(f\"The balanced accuracy score is: {balanced_accuracy_score(y_test, predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55623e8-8e3b-49c8-a3d3-783cad3dc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm_brf = confusion_matrix(y_test, predictions)\n",
    "cm_brf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52c9b0-8cfe-44c6-a3a2-2114652488d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_brf,display_labels= brf_model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# save the image\n",
    "plt.savefig(\"./Images/BalancedRandomForestClassifier_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e710f-fcd3-45a7-b9f4-b25c14cf8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "BalancedRandomForestClassifier_report = classification_report(y_test, predictions)\n",
    "print(\"BalancedRandomForestClassifier\")\n",
    "print(BalancedRandomForestClassifier_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e02b3-52d3-402d-a158-8042765c41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importance_features = brf_model.feature_importances_\n",
    "\n",
    "# put this together in a dataframe\n",
    "# get the column names\n",
    "cols = X_encoded.columns\n",
    "\n",
    "# create the dataframe\n",
    "importance_features_df = pd.DataFrame({'feature': cols, 'importance': importance_features})\n",
    "importance_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad173268-ecd7-469c-9713-527ee981f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in desc order\n",
    "print(\"Feature Importance BalancedRandomForestClassifier\")\n",
    "top_ten_importance_features_df = importance_features_df.sort_values('importance', ascending=False)\n",
    "top_ten_importance_features_df.reset_index(drop=True, inplace=True)\n",
    "top_ten_importance_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc8b8e-6e9a-439e-ada7-63e3c4fe776a",
   "metadata": {},
   "source": [
    "### Easy Ensemble AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a50b1-18f3-4423-a793-9b2c993461c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "\n",
    "# model\n",
    "ee_clf = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# fit/train\n",
    "ee_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = ee_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06466c-5369-47c3-821d-f2975a45d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3e01d-9d22-43f5-a39c-34a0d30f6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm_AdaBoost = confusion_matrix(y_test, y_pred)\n",
    "cm_AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94bef5-aa27-4eec-ab90-f727e55f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_AdaBoost,display_labels= ee_clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# save the image\n",
    "plt.savefig(\"./Images/EasyEnsembleClassifier_confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e6496-c4ba-4ad2-a838-4c343b0a582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "EasyEnsembleClassifier_classification_report = classification_report(y_test, y_pred)\n",
    "print(\"EasyEnsembleClassifier\")\n",
    "print(EasyEnsembleClassifier_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69132fb-ef2f-4c90-834f-d7a346a7846d",
   "metadata": {},
   "source": [
    "#### What is the shape of the training_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d639a-43aa-4ab3-87ad-6d2c6f53eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape of training_df\n",
    "training_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db89cb8-aaae-4a05-8157-8c5cdf46cac5",
   "metadata": {},
   "source": [
    "#### What are the dtypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e54e0-4f6e-4de3-af50-eaf8e9bc41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine missing values and dtypes using info()\n",
    "training_df.info()\n",
    "\n",
    "# note there are missing values for almost every column except the target \"Transported\" and PassengerId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d19cf0-85ab-470f-9f68-04edb85e5a91",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac3c3b-77af-4532-b188-47d7a9745693",
   "metadata": {},
   "source": [
    "### Define the model.\n",
    "### Add first and second hidden layers.\n",
    "### Add the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb60d6-c3e5-4d86-ab32-68e6c0d89d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many inputs in the input layer\n",
    "inputs = len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1866e93-11cc-4a85-8c1a-ea71dc996f3c",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b5d8a-ef05-43f3-a3f1-c28485acbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = inputs\n",
    "hidden_nodes_layer1 = inputs * 3\n",
    "hidden_nodes_layer2 = inputs * 2\n",
    "hidden_nodes_layer3 = inputs * 1\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"sigmoid\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21929140-9048-472b-a9f4-d3cdbe4715c2",
   "metadata": {},
   "source": [
    "### Implement Checkpoints\n",
    "Note: Create a callback that saves the model's weights every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad122d27-06d9-4bb1-bc8e-501b3076346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "# import os\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"Checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d823001-76e5-46ff-a6f3-9bcadc485191",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e40e1-8959-44d7-bca7-2c7981d93d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b503599-7f3e-4231-8ad1-87fcea003b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every epoch (set  5)\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b12eb-6444-40c2-a05e-ecfd2d3524a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train, y_train, epochs=50, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa0933-6626-4760-b482-87030e717d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ff883-9dc2-4db6-aadb-56e58e876620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed2d53b-c40e-403f-b525-722b58ac7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test, y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164ef14-5133-4d38-80b3-15900ad7f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"./Trained_Models/DeepNeuralNetwork.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb7ac4-9c24-42c9-afc9-b1a6e6f837f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3da5fc-9495-4f32-8057-a0d89a9e24c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03721864-f7c4-44d8-935d-4bd67f84dd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e828e-6fb5-4690-8b3a-64ce452697e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dfc5ae-961b-41cd-a28d-a2322751d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db74ff-3bf2-4780-a5e9-e7a608e3b04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d62eb5-488f-4ef7-8499-89f27d8a72e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

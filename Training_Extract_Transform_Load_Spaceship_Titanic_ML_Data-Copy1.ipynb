{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a95da3-9afb-42f7-9be3-552ed6215ec3",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f622c-78ad-4fdc-8e40-62e6bc6b54ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Potential Strategies for replacing missing values and combined columns:\n",
    "* HomePlanet (201)\n",
    "    - Inital Strategy: Impute missing values for HomePlanet with 'most_frequent'  - Earth\n",
    "    - Follow-on Strategy: Use Supervised Classification to predict missing HomePlanet<br><br>\n",
    "    \n",
    "* CryoSleep (217)\n",
    "    - Inital Strategy: Impute CryoSleep with 'most_frequent' - False\n",
    "    - Follow-on Strategy: Use KKN to Classify missing CryoSleep<br><br>\n",
    "    \n",
    "* Cabin (199)\n",
    "    - Inital Strategy: Drop missing values then decompose Cabin into deck, num, side\n",
    "    - Follow-on Strategy: Use KNN to Classify missing Cabin<br><br>\n",
    "\n",
    "* Destination (182)\n",
    "    - Inital Strategy: Impute Destination with 'most_frequent' - TRAPPIST-1e\n",
    "    - Follow-on Strategy: Use Supervised Classification to predict missing Destination<br><br>\n",
    "    \n",
    "* Age (179)\n",
    "    - Inital Strategy: Imput Age with 'most_frequent' (median age) - 27\n",
    "    - Follow-on Strategy: Use Supervised Regression to predict missing Age<br><br>\n",
    "\n",
    "* VIP (203)\n",
    "    - Inital Strategy: Impute VIP status with 'most_frequent' - False\n",
    "    - Follow-on Stragegy: Use KKN to Classify missing VIP status<br><br>\n",
    "\n",
    "* RoomService (181), FoodCourt (183), ShoppingMall (208), Spa (183), VRDeck (188)\n",
    "    - Inital Strategy: Impute missing values for RoomService, FoodCourt, ShoppingMall, Spa, VRDeck with 0<br><br>\n",
    "\n",
    "* Name (200) \n",
    "    - Inital Strategy: Drop missing values then just keep last name\n",
    "    - Follow-on Strategy: Use unsupervised learning to bin names and then classify the 'class' using K-Nearest Neighbor<br><br>\n",
    "\n",
    "* PassengerId (0)\n",
    "    - Inital Strategy: use string.split to split into GroupId and GroupCount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f8b4b8-c064-4e67-9705-b949cfcdb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81c75b6-45ff-43a7-a58b-6a59f898b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from numpy import asarray\n",
    "\n",
    "# import from sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# import sklearn dependencies\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c98f8ee-f69c-4c8c-92d1-6fe557797695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Data/train.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a path to the passenger_list\n",
    "file_path = \"./Data/\"\n",
    "file_name = \"train.csv\"\n",
    "passenger_list = os.path.join(file_path, file_name)\n",
    "passenger_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159149c4-26d4-46e7-8d3e-7b066e76ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in passenger_list csv file as an argument\n",
    "def extract_transform_load(passenger_list):\n",
    "    # Read in the passenger list (train.csv)\n",
    "    passenger_list_df = pd.read_csv(passenger_list)\n",
    "    \n",
    "    # set PassengerId as the dataframe index\n",
    "    passenger_list_df.set_index('PassengerId', inplace=True, drop=False)\n",
    "    \n",
    "    # drop rows with missing values\n",
    "    passenger_list_df.dropna(how='any', inplace=True)\n",
    "    \n",
    "    # breakout GroupId and Count_in_Group from PassengerId\n",
    "    passenger_list_df = passenger_list_df.copy()\n",
    "    passenger_list_df[['GroupId', 'Count_in_Group']] = passenger_list_df['PassengerId'].str.split(\"_\", expand=True)\n",
    "    \n",
    "    # take steps to convert 'Count_in_Group' to Group_Size\n",
    "    # recast 'Count_in_Group' to int\n",
    "    passenger_list_df['Count_in_Group'] = passenger_list_df['Count_in_Group'].astype(int)\n",
    "    \n",
    "    # convert GroupId to numeric\n",
    "    passenger_list_df['GroupId'] = pd.to_numeric(passenger_list_df['GroupId'])\n",
    "    \n",
    "    # get list of GroupId (to iterate over)\n",
    "    Group_Ids = list(passenger_list_df['GroupId'])\n",
    "    \n",
    "    # create new column called Group_Size (max Count_in_Group) for each unique GroupId\n",
    "    # use list comprehension\n",
    "    passenger_list_df['Group_Size'] = [max(passenger_list_df.loc[passenger_list_df['GroupId'] == Group_Id]['Count_in_Group']) for Group_Id in Group_Ids]\n",
    "                                               \n",
    "    # drop Name\n",
    "    passenger_list_df.drop(columns=['Name'], inplace=True)\n",
    "    \n",
    "    # breakout 'Side', 'Deck', 'Cabin_Number' from Cabin\n",
    "    passenger_list_df[[\"Deck\", \"Cabin_Number\", \"Side\"]] = passenger_list_df['Cabin'].str.split(\"/\", expand=True)\n",
    "    \n",
    "    # drop Cabin\n",
    "    passenger_list_df.drop(columns=['Cabin'], inplace=True)    \n",
    " \n",
    "     # to columns to numeric using LabelEncoder\n",
    "    # convert 'Transported' (a boolean) \n",
    "    # and 'Side' (an object) \n",
    "    # and 'Deck' (an object)\n",
    "    # and 'VIP' (an object)\n",
    "    # and 'CryoSleep' (an object)\n",
    "    # and 'HomePlanet' (an object)\n",
    "    # and Destination (an object)\n",
    "   \n",
    "    columns_to_convert = ['Transported', 'Side', 'Deck', 'VIP', 'CryoSleep', 'HomePlanet', 'Destination']\n",
    "    for column in columns_to_convert:\n",
    "        # define labelEncoder encoding\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # fit and transform the data into numeric using LabelEncoder()\n",
    "        passenger_list_df[column] = label_encoder.fit_transform(passenger_list_df[column])\n",
    "    \n",
    "    #     # fit and transform 'Side' into numeric using LabelEncoder()\n",
    "    #     passenger_list_df['Side'] = label_encoder.fit_transform(passenger_list_df['Side'])\n",
    "\n",
    "    #     # fit and transform 'Deck' into numeric using LabelEncoder()\n",
    "    #     passenger_list_df['Deck'] = label_encoder.fit_transform(passenger_list_df['Deck'])\n",
    "\n",
    "    #     # fit and transform 'VIP' into numeric using LabelEncoder()\n",
    "    #     passenger_list_df['VIP'] = label_encoder.fit_transform(passenger_list_df['VIP'])\n",
    "\n",
    "    #     # fit and transform 'CryoSleep' into numeric using LabelEncoder()\n",
    "    #     passenger_list_df['CryoSleep'] = label_encoder.fit_transform(passenger_list_df['CryoSleep'])\n",
    "\n",
    "    #     # fit and transform 'HomePlanet' to an numeric using LabelEncoder()\n",
    "    #     passenger_list_df['HomePlanet'] = label_encoder.fit_transform(passenger_list_df['HomePlanet'])\n",
    "\n",
    "    #     # fit and transform 'Destination' to a numeric using LabelEncoder()\n",
    "    #     passenger_list_df['Destination'] = label_encoder.fit_transform(passenger_list_df['Destination'])\n",
    "    \n",
    "    # convert Cabin_Number to an int\n",
    "    passenger_list_df['Cabin_Number'] = passenger_list_df['Cabin_Number'].astype(int)\n",
    "       \n",
    "    # reorder columns\n",
    "    columns = ['GroupId', 'Group_Size', 'HomePlanet', 'Destination', 'Side', 'Deck', 'Cabin_Number', 'Age', 'CryoSleep', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Transported']\n",
    "    passenger_list_df = passenger_list_df[columns]   \n",
    "    \n",
    "    # save the clean_passenger_list_df as a csv file\n",
    "    passenger_list_df.to_csv(\"./Data/clean_train_passenger_list.csv\")\n",
    "    \n",
    "    # return the passenger_list_df dataframe\n",
    "    # return passenger_list_df\n",
    "    \n",
    "    ###################### LOAD ####################################\n",
    "    # Store environmental variable\n",
    "    from getpass import getpass\n",
    "    password = getpass('Enter database password')\n",
    "    # create connection to our local server\n",
    "    db_string = f\"postgresql://postgres:{password}@127.0.0.1:5435/starship_titanic_db\"\n",
    "    \n",
    "    # create the database engine using from sqlalchemy import create_engine\n",
    "    engine = create_engine(db_string)\n",
    "    \n",
    "    # save the movies_df DataFrame to a SQL table, we only have to specify the name of the table and the engine in the to_sql() method.\n",
    "    # Use 'replace' for the if_exists parameter so that the movies_df DataFrame data won't be added to the table again (if it already exists).\n",
    "    passenger_list_df.to_sql(name='train_passenger_list', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a322bc1c-fc02-41d9-abdf-6c7834387799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter database password ············\n"
     ]
    }
   ],
   "source": [
    "# call the extract_transform_load function\n",
    "passenger_list_df = extract_transform_load(passenger_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
